"""
M√≥dulo Report Metrics: Genera un informe detallado de m√©tricas del procesamiento.
Incluye costes, riesgos de alucinaciones, verificaciones, fuentes y calidad.
"""
from typing import Dict, List, Any, Optional
from datetime import datetime
from .cost_calculator import calculate_total_cost_from_state, calculate_costs_by_role_from_state
from .config import (
    CURRENT_PLANNER_MODEL, CURRENT_JUDGE_MODEL, CURRENT_ANALYST_MODEL,
    CURRENT_CONSOLIDATOR_MODEL, VERIFIER_ENABLED
)
from .state import ResearchState


def generate_execution_metrics_report(state: ResearchState, topic: str) -> str:
    """
    Genera un informe detallado de m√©tricas del procesamiento.
    
    Args:
        state: Estado final del procesamiento
        topic: Tema del reporte
    
    Returns:
        Informe en formato Markdown
    """
    validated_sources = state.get('validated_sources', [])
    rejected_sources = state.get('rejected_sources', [])
    found_sources = state.get('found_sources', [])
    final_report = state.get('final_report', '')
    tokens_by_role = state.get('tokens_by_role', {})
    quality_gate_passed = state.get('quality_gate_passed', False)
    quality_gate_issues = state.get('quality_gate_issues', [])
    confidence_score = state.get('confidence_score', {})
    plot_data = state.get('plot_data', [])
    
    # Calcular costes
    total_cost = calculate_total_cost_from_state(state)
    costs_by_role = calculate_costs_by_role_from_state(state)
    
    # Analizar fuentes
    total_sources_found = len(found_sources)
    total_sources_validated = len(validated_sources)
    total_sources_rejected = len(rejected_sources)
    
    # Calidad de fuentes
    if validated_sources:
        avg_reliability = sum(s.get('reliability_score', 0) for s in validated_sources) / len(validated_sources)
        avg_authenticity = sum(s.get('authenticity_score', 0) for s in validated_sources) / len(validated_sources)
        avg_relevance = sum(s.get('relevance_score', 0) for s in validated_sources) / len(validated_sources)
        avg_total_score = sum(s.get('total_score', 0) for s in validated_sources) / len(validated_sources)
        
        # Fuentes de √©lite
        elite_sources = [s for s in validated_sources if s.get('fast_track') == 'elite']
        elite_count = len(elite_sources)
        
        # Fuentes con evaluaci√≥n MiMo vs Gemini
        mimo_evaluated = [s for s in validated_sources if s.get('pre_judge') == 'mimo']
        gemini_evaluated = [s for s in validated_sources if s.get('pre_judge') == 'gemini']
        
        # Distribuci√≥n por dominio
        domain_distribution = {}
        for source in validated_sources:
            domain = source.get('source_domain', 'Unknown')
            domain_distribution[domain] = domain_distribution.get(domain, 0) + 1
        
        # Fuentes con evidencias extra√≠das
        sources_with_evidence = [s for s in validated_sources if s.get('extracted') and s.get('evidence_points')]
        evidence_extraction_rate = len(sources_with_evidence) / len(validated_sources) * 100 if validated_sources else 0
    else:
        avg_reliability = 0
        avg_authenticity = 0
        avg_relevance = 0
        avg_total_score = 0
        elite_count = 0
        mimo_evaluated = []
        gemini_evaluated = []
        domain_distribution = {}
        sources_with_evidence = []
        evidence_extraction_rate = 0
    
    # An√°lisis de verificaci√≥n
    verification_info = {
        "enabled": VERIFIER_ENABLED,
        "issues_found": 0,
        "issues_high_severity": 0,
        "issues_medium_severity": 0,
        "issues_low_severity": 0,
        "references_validated": False,
        "references_issues": [],
        "verification_passed": False
    }
    
    # Buscar informaci√≥n de verificaci√≥n en el estado (si est√° disponible)
    verification_issues = state.get('verification_issues', [])
    if verification_issues:
        verification_info["issues_found"] = len(verification_issues)
        verification_info["issues_high_severity"] = state.get('verification_high_severity_count', 0)
        verification_info["issues_medium_severity"] = state.get('verification_medium_severity_count', 0)
        verification_info["issues_low_severity"] = state.get('verification_low_severity_count', 0)
        verification_info["verification_passed"] = state.get('verification_passed', False)
    
    ref_validation = state.get('references_validation', {})
    if ref_validation:
        verification_info["references_validated"] = ref_validation.get('passed', False)
        verification_info["references_issues"] = ref_validation.get('issues', [])
    elif 'references_validation_passed' in state:
        verification_info["references_validated"] = state.get('references_validation_passed', False)
    
    # An√°lisis del reporte
    report_length = len(final_report) if final_report else 0
    report_words = len(final_report.split()) if final_report else 0
    
    # Contar citas en el reporte
    import re
    citations_pattern = re.compile(r'\[(\d+(?:,\s*\d+)*)\]')
    citations_found = citations_pattern.findall(final_report) if final_report else []
    total_citations = len(citations_found)
    
    # Buscar secci√≥n de referencias
    has_references_section = bool(re.search(r'## References\s*\n', final_report, re.IGNORECASE)) if final_report else False
    
    # Calcular tokens totales
    total_tokens = sum(tokens_by_role.values())
    
    # An√°lisis de riesgos de alucinaci√≥n
    hallucination_risks = []
    risk_score = 0  # 0-100, mayor = m√°s riesgo
    
    # Riesgo 1: Pocas fuentes
    if total_sources_validated < 3:
        hallucination_risks.append({
            "risk": "Bajo n√∫mero de fuentes",
            "severity": "MEDIUM",
            "description": f"Solo {total_sources_validated} fuente(s) validadas. M√∫ltiples fuentes reducen el riesgo de alucinaci√≥n."
        })
        risk_score += 20
    
    # Riesgo 2: Fuentes de baja calidad
    if validated_sources and avg_total_score < 6:
        hallucination_risks.append({
            "risk": "Fuentes de baja calidad promedio",
            "severity": "HIGH",
            "description": f"Score promedio: {avg_total_score:.1f}/10. Fuentes poco confiables aumentan el riesgo de alucinaci√≥n."
        })
        risk_score += 30
    
    # Riesgo 3: Sin verificaci√≥n habilitada
    if not VERIFIER_ENABLED:
        hallucination_risks.append({
            "risk": "Verificador de alucinaciones deshabilitado",
            "severity": "MEDIUM",
            "description": "El verificador post-generaci√≥n est√° deshabilitado. No se realiz√≥ validaci√≥n autom√°tica contra fuentes."
        })
        risk_score += 15
    
    # Riesgo 4: Issues de verificaci√≥n encontrados
    if verification_info["issues_found"] > 0:
        hallucination_risks.append({
            "risk": "Problemas detectados en verificaci√≥n",
            "severity": "HIGH" if verification_info["issues_high_severity"] > 0 else "MEDIUM",
            "description": f"{verification_info['issues_found']} problema(s) encontrado(s), {verification_info['issues_high_severity']} de alta severidad."
        })
        risk_score += min(verification_info["issues_found"] * 5, 35)
    
    # Riesgo 5: Problemas con referencias
    if not verification_info["references_validated"]:
        hallucination_risks.append({
            "risk": "Validaci√≥n de referencias fallida",
            "severity": "MEDIUM",
            "description": f"Se detectaron {len(verification_info['references_issues'])} problema(s) con la secci√≥n de referencias."
        })
        risk_score += 15
    
    # Determinar nivel de riesgo
    if risk_score >= 60:
        risk_level = "ALTO"
        risk_emoji = "üî¥"
    elif risk_score >= 30:
        risk_level = "MEDIO"
        risk_emoji = "üü°"
    else:
        risk_level = "BAJO"
        risk_emoji = "üü¢"
    
    # Generar informe
    report = f"""# üìä Informe de M√©tricas de Ejecuci√≥n

**Tema:** {topic}  
**Fecha de generaci√≥n:** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}  
**Estado:** {'‚úÖ Completado exitosamente' if not state.get('error') else '‚ùå Error en procesamiento'}

---

## üí∞ An√°lisis de Costes

### Coste Total: ${total_cost:.6f}

### Desglose por Agente:

"""
    
    # Agregar costes por rol
    for role, cost in sorted(costs_by_role.items(), key=lambda x: x[1], reverse=True):
        if cost > 0:
            role_name = role.capitalize().replace('_', ' ')
            report += f"- **{role_name}**: ${cost:.6f}"
            
            # A√±adir modelo usado
            if role == "planner":
                report += f" (Modelo: {CURRENT_PLANNER_MODEL})"
            elif role == "judge":
                report += f" (Modelo: {CURRENT_JUDGE_MODEL})"
            elif role == "analyst":
                report += f" (Modelo: {CURRENT_ANALYST_MODEL})"
            
            report += "\n"
    
    # Costes de b√∫squeda (Tavily/Exa)
    # Estimaci√≥n aproximada: Tavily $0.01 por b√∫squeda, Exa $0.10 por b√∫squeda
    search_queries = len(state.get('search_strategy', []))
    tavily_cost = search_queries * 0.01  # Estimaci√≥n conservadora
    report += f"- **B√∫squeda Web (Tavily/Exa)**: ~${tavily_cost:.4f} (estimaci√≥n, {search_queries} query(s))\n"
    
    total_cost_with_search = total_cost + tavily_cost
    report += f"\n**üíµ Coste Total Estimado (LLM + B√∫squeda):** ${total_cost_with_search:.6f}\n"
    
    report += f"""
### Uso de Tokens:

- **Total de tokens:** {total_tokens:,}
- **Desglose por rol:**
"""
    
    for role, tokens in sorted(tokens_by_role.items(), key=lambda x: x[1], reverse=True):
        if tokens > 0:
            role_name = role.capitalize().replace('_', ' ')
            percentage = (tokens / total_tokens * 100) if total_tokens > 0 else 0
            report += f"  - {role_name}: {tokens:,} tokens ({percentage:.1f}%)\n"
    
    report += f"""
---

## {risk_emoji} An√°lisis de Riesgos de Alucinaci√≥n

**Nivel de Riesgo General:** {risk_level} ({risk_score}/100)

### Riesgos Identificados:

"""
    
    if hallucination_risks:
        for i, risk in enumerate(hallucination_risks, 1):
            severity_emoji = "üî¥" if risk["severity"] == "HIGH" else "üü°" if risk["severity"] == "MEDIUM" else "üü¢"
            report += f"{i}. {severity_emoji} **{risk['risk']}** ({risk['severity']})\n"
            report += f"   {risk['description']}\n\n"
    else:
        report += "‚úÖ No se identificaron riesgos significativos de alucinaci√≥n.\n\n"
    
    report += f"""
### Mitigaciones Implementadas:

‚úÖ **Salvaguardas Anti-Alucinaci√≥n:**
- Reglas estrictas en prompts del Reporter (prohibici√≥n expl√≠cita de inventar datos)
- Evaluaci√≥n multidimensional de fuentes (Authenticity, Reliability, Relevance, Currency)
- Extracci√≥n de evidencias antes de evaluaci√≥n (reducci√≥n de ruido)
- Verificaci√≥n post-generaci√≥n: {'‚úÖ Habilitada' if VERIFIER_ENABLED else '‚ùå Deshabilitada'}
- Validaci√≥n de referencias: {'‚úÖ Pasada' if verification_info['references_validated'] else '‚ùå Fallida o no realizada'}

‚úÖ **Optimizaci√≥n de Evaluaci√≥n:**
- Pre-juez con MiMo-V2-Flash (barato) para triage inicial
- Escalamiento a Gemini 2.5 Pro solo para casos cr√≠ticos/inciertos
- Fast-track para dominios de √©lite (sin LLM)
- Cache de evaluaciones previas

"""

    if mimo_evaluated and gemini_evaluated:
        report += f"   - Fuentes evaluadas con MiMo: {len(mimo_evaluated)} ({len(mimo_evaluated)/total_sources_validated*100:.1f}%)\n"
        report += f"   - Fuentes evaluadas con Gemini: {len(gemini_evaluated)} ({len(gemini_evaluated)/total_sources_validated*100:.1f}%)\n"
        report += f"   - Ahorro estimado: ~${len(mimo_evaluated) * 0.001:.4f} (usando MiMo en lugar de Gemini para todas)\n\n"

    report += f"""
---

## ‚úÖ Verificaciones Realizadas

### 1. Verificaci√≥n de Alucinaciones:

- **Estado:** {'‚úÖ Realizada' if VERIFIER_ENABLED else '‚ùå No realizada'}
- **Problemas encontrados:** {verification_info['issues_found']}
- **Problemas de alta severidad:** {verification_info['issues_high_severity']}

"""

    if verification_info['issues_found'] > 0:
        report += "**‚ö†Ô∏è Problemas detectados:**\n"
        for i, issue in enumerate(state.get('verification_issues', [])[:5], 1):
            report += f"  {i}. [{issue.get('severity', 'unknown').upper()}] {issue.get('type', 'unknown')}: {issue.get('text', '')[:60]}...\n"
        if verification_info['issues_found'] > 5:
            report += f"  ... y {verification_info['issues_found'] - 5} m√°s\n"
    
    report += f"""
### 2. Validaci√≥n de Referencias:

- **Estado:** {'‚úÖ Pasada' if verification_info['references_validated'] else '‚ùå Fallida'}
- **Citas en el texto:** {total_citations}
- **Secci√≥n References presente:** {'‚úÖ S√≠' if has_references_section else '‚ùå No'}

"""

    if not verification_info['references_validated']:
        if verification_info['references_issues']:
            report += "**Problemas encontrados:**\n"
            for i, issue in enumerate(verification_info['references_issues'][:5], 1):
                report += f"  {i}. {issue}\n"
            if len(verification_info['references_issues']) > 5:
                report += f"  ... y {len(verification_info['references_issues']) - 5} m√°s\n"
        else:
            # Si fall√≥ pero no hay issues en el estado, intentar obtenerlos de otra forma
            ref_validation = state.get('references_validation', {})
            if ref_validation and ref_validation.get('issues'):
                report += "**Problemas encontrados:**\n"
                for i, issue in enumerate(ref_validation['issues'][:5], 1):
                    report += f"  {i}. {issue}\n"
                if len(ref_validation['issues']) > 5:
                    report += f"  ... y {len(ref_validation['issues']) - 5} m√°s\n"
            else:
                report += "**‚ö†Ô∏è Validaci√≥n fall√≥ pero no se pudieron obtener detalles espec√≠ficos.**\n"
                # Mostrar informaci√≥n disponible para debugging
                if ref_validation:
                    report += f"  - Citas encontradas: {ref_validation.get('citation_count', 'N/A')}\n"
                    report += f"  - Referencias en ## References: {ref_validation.get('reference_count', 'N/A')}\n"
                    report += f"  - Fuentes faltantes: {len(ref_validation.get('missing_sources', []))}\n"
                    report += f"  - Citas inv√°lidas: {len(ref_validation.get('invalid_citations', []))}\n"

    report += f"""
### 3. Quality Gate:

- **Estado:** {'‚úÖ Pasado' if quality_gate_passed else '‚ùå Fallido'}
- **Confianza del sistema:** {confidence_score.get('score', 'N/A')}/100

"""

    if quality_gate_issues:
        report += "**Issues detectados:**\n"
        for issue in quality_gate_issues[:5]:
            report += f"  - {issue}\n"

    report += f"""
---

## üìö An√°lisis de Fuentes

### Resumen General:

- **Fuentes encontradas:** {total_sources_found}
- **Fuentes validadas:** {total_sources_validated}
- **Fuentes rechazadas:** {total_sources_rejected}
- **Tasa de aceptaci√≥n:** {(total_sources_validated / total_sources_found * 100) if total_sources_found > 0 else 0:.1f}%

### Calidad de Fuentes Validadas:

- **Score promedio:** {avg_total_score:.1f}/10
- **Authenticity promedio:** {avg_authenticity:.1f}/10
- **Reliability promedio:** {avg_reliability:.1f}/10
- **Relevance promedio:** {avg_relevance:.1f}/10

**Distribuci√≥n por calidad:**
"""

    if validated_sources:
        high_quality = len([s for s in validated_sources if s.get('total_score', 0) >= 8])
        medium_quality = len([s for s in validated_sources if 6 <= s.get('total_score', 0) < 8])
        low_quality = len([s for s in validated_sources if s.get('total_score', 0) < 6])
        
        report += f"- üü¢ Alta calidad (‚â•8): {high_quality} ({high_quality/total_sources_validated*100:.1f}%)\n"
        report += f"- üü° Calidad media (6-7): {medium_quality} ({medium_quality/total_sources_validated*100:.1f}%)\n"
        report += f"- üî¥ Baja calidad (<6): {low_quality} ({low_quality/total_sources_validated*100:.1f}%)\n"
        
        report += f"\n**Fuentes de √©lite (Tier 1-2):** {elite_count} ({elite_count/total_sources_validated*100:.1f}%)\n"

    report += f"""
### Extracci√≥n de Evidencias:

- **Fuentes con evidencias extra√≠das:** {len(sources_with_evidence)}/{total_sources_validated}
- **Tasa de extracci√≥n:** {evidence_extraction_rate:.1f}%

### Distribuci√≥n por Dominio:

"""

    if domain_distribution:
        sorted_domains = sorted(domain_distribution.items(), key=lambda x: x[1], reverse=True)
        for domain, count in sorted_domains[:10]:  # Top 10 dominios
            percentage = (count / total_sources_validated * 100) if total_sources_validated > 0 else 0
            report += f"- `{domain}`: {count} fuente(s) ({percentage:.1f}%)\n"
    
    report += f"""
---

## üìù An√°lisis del Reporte Final

- **Longitud:** {report_length:,} caracteres
- **Palabras:** {report_words:,} palabras
- **Citas en el texto:** {total_citations}
- **Referencias listadas:** {'‚úÖ S√≠' if has_references_section else '‚ùå No'}

### Elementos del Reporte:

"""

    # Verificar elementos del reporte (Confidence Score no se reporta como issue, el judge ya hizo su trabajo)
    has_plots = len(plot_data) > 0
    
    report += f"- Gr√°ficos generados: {len(plot_data)} ({'‚úÖ Presentes' if has_plots else '‚ùå Ninguno'})\n"
    report += f"- Secci√≥n de referencias: {'‚úÖ Presente' if has_references_section else '‚ùå Ausente'}\n"
    
    report += f"""
---

## üîß M√©tricas de Procesamiento

### Optimizaciones Aplicadas:

- **Cache de evaluaciones:** ‚úÖ Activo (reducci√≥n de llamadas LLM redundantes)
- **Fast-track √©lite:** ‚úÖ Activo (evaluaci√≥n sin LLM para dominios reconocidos)
- **Extracci√≥n de evidencias:** ‚úÖ Activa (pre-procesamiento antes de evaluaci√≥n)
- **Pre-juez con MiMo:** ‚úÖ Activo (evaluaci√≥n preliminar barata)
- **Escalamiento selectivo:** ‚úÖ Activo (Gemini solo para casos cr√≠ticos)

### Rendimiento:

- **Loops de b√∫squeda:** {state.get('loop_count', 0)}
- **Queries ejecutadas:** {search_queries}
- **Quality gate:** {'‚úÖ Pasado' if quality_gate_passed else '‚ùå Fallido'}

---

## üìã Recomendaciones

"""

    recommendations = []
    
    if risk_score >= 60:
        recommendations.append("üî¥ **URGENTE**: Revisar manualmente el reporte por alto riesgo de alucinaci√≥n.")
    elif risk_score >= 30:
        recommendations.append("üü° **IMPORTANTE**: Revisar las secciones con problemas detectados.")
    
    if total_sources_validated < 3:
        recommendations.append(f"üü° Considerar buscar m√°s fuentes (actualmente {total_sources_validated}).")
    
    if avg_total_score < 6:
        recommendations.append(f"üü° Mejorar calidad de fuentes (score promedio: {avg_total_score:.1f}/10).")
    
    if not VERIFIER_ENABLED:
        recommendations.append("üü° Habilitar verificador de alucinaciones para mayor seguridad.")
    
    if verification_info['issues_found'] > 0:
        recommendations.append(f"üü° Revisar {verification_info['issues_found']} problema(s) detectado(s) en verificaci√≥n.")
    
    if not verification_info['references_validated']:
        recommendations.append("üü° Corregir problemas en la secci√≥n de referencias.")
    
    if recommendations:
        for i, rec in enumerate(recommendations, 1):
            report += f"{i}. {rec}\n"
    else:
        report += "‚úÖ **No se requieren acciones inmediatas.** El reporte cumple con los est√°ndares de calidad.\n"
    
    report += f"""
---

**Fin del Informe de M√©tricas**

*Generado autom√°ticamente por el sistema de investigaci√≥n Deep Research*
"""
    
    return report
