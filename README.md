# LetsInnovate: Deep Research Platform

![LetsInnovate Cover](assets/lets_cover.png)

![Python Version](https://img.shields.io/badge/Python-3.10.19-blue.svg)
![Framework](https://img.shields.io/badge/Framework-LangGraph-orange.svg)
![Status](https://img.shields.io/badge/Status-Active-green.svg)
![License](https://img.shields.io/badge/License-Proprietary-red.svg)

**Sistema de investigaci√≥n aut√≥noma basado en agentes de IA para la generaci√≥n de informes empresariales ultra-personalizados**

---

## üéØ ¬øQu√© hace esta herramienta tan potente?

El **Deep Research Agent** no es simplemente un generador de documentos. Es una **plataforma de inteligencia estrat√©gica** que combina el poder de m√∫ltiples modelos de IA (GPT-4, Gemini 2.5 Pro, Claude) con b√∫squeda especializada en la web profunda para crear informes de investigaci√≥n completamente personalizados.

### El Secreto: **T√≠tulo + √çndice + Agente = Informe Perfecto**

La verdadera potencia de esta herramienta reside en c√≥mo **orientas** tus investigaciones:

1. **El T√≠tulo del Item** ‚Üí Define el enfoque y perspectiva del cap√≠tulo
2. **El √çndice del Proyecto** ‚Üí Estructura la narrativa y determina qu√© aspectos profundizar
3. **El Agente (System Prompt)** ‚Üí Personaliza el tono, profundidad t√©cnica y estilo

**Ejemplo pr√°ctico:**

Imagina que quieres investigar "IA en el sector salud". Dependiendo de c√≥mo lo orientes:

| T√≠tulo Item | √çndice Proyecto | Agente | Resultado |
|-------------|-----------------|--------|-----------|
| "Implementaci√≥n de IA en hospitales" | - Casos de uso<br>- ROI<br>- Regulaciones | Consultor Estrat√©gico | Informe ejecutivo con enfoque en adopci√≥n empresarial |
| "Algoritmos de diagn√≥stico por IA" | - Arquitecturas ML<br>- Datasets<br>- M√©tricas | Investigador T√©cnico | An√°lisis profundo de modelos y rendimiento |
| "Impacto de IA en pacientes" | - Experiencia usuario<br>- √âtica<br>- Privacidad | Analista Social | Perspectiva human√≠stica y social |

**El mismo tema, tres documentos completamente diferentes.** Esta es la versatilidad que ofrece el sistema.

---

## üìö Tabla de Contenidos

1. [Arquitectura del Sistema](#Ô∏è-arquitectura-del-sistema)
2. [Proceso de Generaci√≥n de Documentos](#-proceso-de-generaci√≥n-de-documentos-paso-a-paso)
3. [Configuraci√≥n Avanzada](#Ô∏è-configuraci√≥n-avanzada-configtoml)
4. [Gesti√≥n mediante Airtable](#-gesti√≥n-mediante-airtable)
5. [Instalaci√≥n](#-instalaci√≥n-y-preparaci√≥n)
6. [Gu√≠a de Uso](#-gu√≠a-de-uso)
7. [Despliegue en Render.com](#-despliegue-en-rendercom)

---

## üèóÔ∏è Arquitectura del Sistema

El sistema opera mediante **6 agentes especializados** que colaboran en un flujo orquestado:

```mermaid
graph TD
    A[Airtable: Items con Status=Todo] --> B[Matcher Agent]
    B --> C[Planner Agent]
    C --> D[Searcher: Tavily/Exa]
    D --> E[Judge Agent]
    E --> F{¬øSuficientes fuentes?}
    F -->|No| C
    F -->|S√≠| G[Analyst Agent]
    G --> H[Items completados]
    H --> I[Consolidator Agent]
    I --> J[Documento Word Final]
```

### Los 6 Agentes y sus Funciones

| Agente | Rol | Modelo | Variables configurables en `config.toml` |
|--------|-----|--------|------------------------------------------|
| **üéØ Matcher** | Analiza el tema y asigna el perfil de experto (System Prompt) m√°s adecuado | `xiaomi/mimo-v2-flash` | `[roles.matcher]` ‚Üí provider, model, temperature |
| **üìã Planner** | Genera estrategias de b√∫squeda y queries optimizadas | `xiaomi/mimo-v2-flash` | `[roles.planner]` + `[search]` ‚Üí max_search_queries |
| **üîç Searcher** | Ejecuta b√∫squedas en la web profunda (Tavily/Exa) | - | `[search]` ‚Üí tavily_search_depth, max_results_per_query, excluded_domains |
| **‚öñÔ∏è Judge** | Eval√∫a calidad de fuentes (relevancia, autoridad, actualidad) | `xiaomi/mimo-v2-flash` | `[roles.judge]` + `[evaluator]` ‚Üí thresholds, min_accepted_sources |
| **‚úçÔ∏è Analyst** | Sintetiza informaci√≥n y redacta cap√≠tulos individuales | `claude-haiku-4.5` | `[roles.analyst]` + `[general]` ‚Üí target_audience, report_language |
| **üìñ Consolidator** | Integra todos los cap√≠tulos en un documento coherent con √≠ndice y referencias | `gemini-2.5-pro` | `[roles.consolidator]` + `[references]` ‚Üí style, enable_hyperlinks |

---

## üîÑ Proceso de Generaci√≥n de Documentos: Paso a Paso

### **Fase 1: Definici√≥n del Proyecto en Airtable**

**¬øQu√© haces?**
1. Creas un registro en la tabla **Proyectos**
2. Defines el **Nombre** del proyecto
3. A√±ades **Items** (cap√≠tulos/temas) relacionados en **Items_indice**
4. Opcionalmente, adjuntas **documentos de contexto** interno (PDFs, DOCX) en el campo `Context`

**Variables relevantes:**
```toml
[context]
source = "airtable"  # Si quieres que descargue docs desde Airtable
# o
source = "local"     # Si prefieres usar carpeta private_context/

[airtable]
proyectos_table_name = "Proyectos"
items_table_name = "Items_indice"
```

**Estado del Proyecto:**
- `Submitted` ‚Üí Proyecto en cola (no se procesa autom√°ticamente)
- `Todo` ‚Üí Listo para procesarse
- `Generating items` ‚Üí Procesando items
- `Processing` ‚Üí Consolidando documento final
- `Done` ‚Üí Completado

---

### **Fase 2: Asignaci√≥n Inteligente de Agentes (Matcher)**

**¬øQu√© hace el sistema?**
- Lee cada item con `Status='Todo'`
- Analiza el **t√≠tulo** y **descripci√≥n** del tema
- Compara con todos los **System Prompts** disponibles
- Selecciona el perfil de experto m√°s adecuado autom√°ticamente
- Actualiza `System_Prompt_Link` y cambia `Status` a `Pending`

**Comando:** `python main.py match` (o autom√°tico con `pipeline`)

**Variables relevantes:**
```toml
[roles.matcher]
provider = "openrouter"
model = "xiaomi/mimo-v2-flash:free"
temperature = 0.0  # 0.0 = determinista, 1.0 = creativo

[airtable]
prompts_table_name = "System_Prompts"
```

**Ejemplo de System Prompts:**
- "Consultor Estrat√©gico Tecnol√≥gico" ‚Üí IA, Digital Transformation, Innovation
- "Analista Financiero Senior" ‚Üí M&A, Valuations, Market Analysis
- "Investigador Acad√©mico" ‚Üí Deep technical research, citations, rigor

---

### **Fase 3: Investigaci√≥n Profunda (Planner + Searcher + Judge)**

Esta es la **fase m√°s cr√≠tica** donde se decide la calidad del informe final.

#### **3.1. Planner: Generaci√≥n de Estrategias de B√∫squeda**

**¬øQu√© hace?**
- Recibe el **tema**, **contexto general de la empresa** y **temas relacionados** (todo el √≠ndice del proyecto)
- Genera m√∫ltiples queries de b√∫squeda optimizadas
- Considera sin√≥nimos, t√©rminos t√©cnicos, perspectivas alternativas

**Variables relevantes:**
```toml
[search]
max_search_queries = 3  # Cu√°ntas b√∫squedas diferentes genera

[general]
target_audience = "CEO/Directivos"  # Influencia el tipo de fuentes a buscar
```

**Ejemplo:**
- Tema: "IA en diagn√≥stico m√©dico"
- Queries generadas:
  1. "AI medical diagnosis algorithms FDA approved 2024"
  2. "deep learning radiology image analysis clinical validation"
  3. "artificial intelligence diagnostic accuracy vs human doctors"

#### **3.2. Searcher: Ejecuci√≥n de B√∫squedas**

**¬øQu√© hace?**
- Ejecuta b√∫squedas en **Tavily** y **Exa** (motores especializados en investigaci√≥n)
- Extrae contenido de p√°ginas web (hasta 4000 caracteres por fuente)
- Filtra dominios excluidos autom√°ticamente

**Variables relevantes:**
```toml
[tools]
tavily_enabled = true
exa_enabled = true

[search]
max_results_per_query = 5  # Resultados por b√∫squeda
max_chars_per_source = 4000  # Texto extra√≠do por fuente
tavily_search_depth = "advanced"  # "basic" (r√°pido) vs "advanced" (exhaustivo)

excluded_domains = [
    "quora.com",
    "reddit.com",
    "wikipedia.org",
    # ... m√°s dominios de baja calidad
]
```

**üí° Tip:** Aumenta `max_results_per_query` a 10 para temas muy espec√≠ficos

#### **3.3. Judge: Evaluaci√≥n de Calidad**

**¬øQu√© hace?**
- Eval√∫a **cada fuente** encontrada seg√∫n 4 criterios:
  1. **Relevancia** (0-10): ¬øResponde directamente al tema?
  2. **Autoridad** (0-10): ¬øEs la fuente confiable y experta?
  3. **Actualidad** (0-10): ¬øEs informaci√≥n reciente?
  4. **Profundidad** (0-10): ¬øOfrece an√°lisis detallado?

- Calcula puntuaci√≥n total (promedio de los 4)
- **Acepta** si supera los umbrales configurados
- **Rechaza** si no cumple los criterios

**Variables relevantes:**
```toml
[evaluator]
total_score_threshold = 8  # Puntuaci√≥n m√≠nima promedio (0-10)
relevance_score_threshold = 8  # Relevancia m√≠nima espec√≠fica
min_accepted_sources = -1  # M√≠nimo de fuentes aceptadas (-1 = sin l√≠mite)

[general]
max_retries = 3  # Reintentos si no hay suficientes fuentes
```

**Feedback Loop:**
Si no se alcanzan suficientes fuentes de calidad ‚Üí vuelve al **Planner** ‚Üí genera nuevas queries ‚Üí repite hasta `max_retries`

---

### **Fase 4: S√≠ntesis y Redacci√≥n (Analyst)**

**¬øQu√© hace?**
- Recibe **todas las fuentes aceptadas**
- Lee el **System Prompt** asignado (perfil de experto)
- Considera el **contexto de la empresa** y **temas relacionados** (todo el √≠ndice)
- Redacta un cap√≠tulo completo y detallado
- Genera autom√°ticamente **gr√°ficos** si `enable_plots = true`
- Incluye **citas IEEE** con n√∫meros `[1], [2]...`

**Variables relevantes:**
```toml
[roles.analyst]
provider = "openrouter"
model = "anthropic/claude-haiku-4.5"  # Modelo con gran ventana de contexto
temperature = 0.0  # 0.0 = factual y riguroso

[general]
target_audience = "CEO/Directivos"  # Adapta vocabulario y profundidad
report_language = "English"  # Idioma de redacci√≥n
enable_plots = true  # Genera gr√°ficos autom√°ticos

[context]
source = "local"  # Usa contexto de private_context/ o Airtable
```

**Estructura del cap√≠tulo generado:**
```markdown
# [T√≠tulo del Item]

[P√°rrafo introductorio rico en contexto]

## 1. Primera Secci√≥n
[Contenido detallado con datos, ejemplos, an√°lisis]

### 1.1. Subsecci√≥n
[Profundizaci√≥n t√©cnica]

## 2. Segunda Secci√≥n
...

## References
[1] Author, "Title", URL
[2] ...
```

**üí° Tip:** Cambia `temperature` a 0.3-0.5 si quieres un estilo m√°s narrativo y menos t√©cnico

---

### **Fase 5: Consolidaci√≥n Final (Consolidator)**

**¬øQu√© hace?**
- Espera a que **todos los items** del proyecto est√©n `Status='Done'`
- Recopila **todos los cap√≠tulos** generados
- Lee la **estructura propuesta** del √≠ndice (todos los t√≠tulos de items)
- Genera:
  - **T√≠tulo principal** del documento
  - **Tabla de contenidos** din√°mica
  - **Executive Summary** (resumen ejecutivo)
  - **Introducci√≥n** contextualizada
  - **Conclusiones** integradoras
  - **Referencias consolidadas** en formato IEEE

- Crea el documento **Word (.docx)** con formato profesional
- Sube a **Cloudflare R2** (si est√° habilitado)
- Vincula el archivo en **Airtable**

**Variables relevantes:**
```toml
[roles.consolidator]
provider = "openrouter"
model = "google/gemini-2.5-pro"  # Ventana de contexto masiva (2M tokens)
temperature = 0.0

[general]
upload_to_r2 = true  # Sube a R2 y vincula en Airtable
target_audience = "CEO/Directivos"
report_language = "English"

[references]
enable_hyperlinks = true  # Citas [1] clicables
style = "IEEE"  # Estilo de referencias

[references.link_style]
font = "Calibri"
size_pt = 10
blue = true
underline = true
```

**Formato Word generado:**
- **Template base:** `assets/template.docx` (estilos profesionales predefinidos)
- **Jerarqu√≠a de headers:** H1 ‚Üí H2 ‚Üí H3 ‚Üí H4
- **Table of Contents** interactiva
- **Im√°genes** (plots) embebidas
- **Referencias clicables** (si enable_hyperlinks = true)

---

## ‚öôÔ∏è Configuraci√≥n Avanzada: `config.toml`

El archivo `config.toml` es el **centro de control** de todo el sistema. Permite personalizar cada aspecto sin tocar c√≥digo.

### 1. **Configuraci√≥n General `[general]`**

```toml
[general]
use_deepseek_for_testing = false  # true = usa DeepSeek (m√°s barato) para todo
target_audience = "CEO/Directivos"  # Adapta tono y profundidad
report_language = "English"  # Idioma del documento
max_retries = 3  # Reintentos si no hay suficientes fuentes
concurrency_limit = 1  # Items procesados simult√°neamente
```

**¬øCu√°ndo modificar?**
- `target_audience`: Cambia seg√∫n qui√©n vaya a leer el documento
  - "CEO/Directivos" ‚Üí Visi√≥n estrat√©gica, ROI, impacto de negocio
  - "Equipo T√©cnico" ‚Üí Detalles de implementaci√≥n, arquitectura, c√≥digo
  - "Analistas Financieros" ‚Üí M√©tricas, valoraciones, proyecciones
  
- `concurrency_limit`: Aumenta a 2-3 si tienes buen hardware y muchos items

---

### 2. **Contexto del Proyecto `[context]`**

```toml
[context]
source = "local"  # "local" o "airtable"
local_folder = "private_context"
```

**Modos disponibles:**

#### **Modo Local (Recomendado para producci√≥n)**
- Coloca archivos `.txt` o `.md` en `private_context/`
- Carga instant√°nea, sin descargas de Airtable
- Ideal para **Render.com** (evita problemas de memoria)

**Ejemplo:**
```bash
private_context/
‚îú‚îÄ‚îÄ company_strategy_2026.md
‚îú‚îÄ‚îÄ product_portfolio.txt
‚îî‚îÄ‚îÄ market_positioning.md
```

#### **Modo Airtable (Para desarrollo)**
- Descarga adjuntos del campo `Context` en tabla Proyectos
- Procesa PDFs/DOCX con **Docling** (pesado, puede fallar en Render free tier)

**¬øCu√°ndo usar cada uno?**
- `local`: Despliegue en Render, contexto fijo, m√°xima velocidad
- `airtable`: Desarrollo local, contexto cambia frecuentemente

---

### 3. **Roles de LLM `[roles.*]`**

Cada agente puede usar un modelo diferente. Ejemplos:

```toml
[roles.planner]
provider = "openrouter"  # "openai", "gemini", "deepseek", "openrouter"
model = "xiaomi/mimo-v2-flash:free"
temperature = 0.0

[roles.analyst]
provider = "openrouter"
model = "anthropic/claude-haiku-4.5"  # Modelo con 200K tokens de contexto
temperature = 0.0
```

**Modelos recomendados por tarea:**
- **Planner/Judge**: Modelos r√°pidos y baratos (`xiaomi/mimo`, `gpt-4o-mini`)
- **Analyst**: Modelos con gran contexto (`claude-haiku`, `gemini-1.5-pro`)
- **Consolidator**: Modelos con contexto masivo (`gemini-2.5-pro` = 2M tokens)

**üí° Optimizaci√≥n de costes:**
```toml
[general]
use_deepseek_for_testing = true  # Usa DeepSeek para todo (testing)
```

---

### 4. **B√∫squeda y Evaluaci√≥n**

```toml
[search]
max_search_queries = 3  # N√∫mero de b√∫squedas por tema
max_results_per_query = 5  # Resultados analizados por b√∫squeda
max_chars_per_source = 4000  # Texto extra√≠do por fuente
tavily_search_depth = "advanced"  # "basic" (r√°pido) o "advanced" (exhaustivo)

excluded_domains = [
    "quora.com",
    "reddit.com",
    # A√±ade m√°s si necesitas
]

[evaluator]
total_score_threshold = 8  # Puntuaci√≥n m√≠nima (0-10)
relevance_score_threshold = 8  # Relevancia espec√≠fica
min_accepted_sources = -1  # M√≠nimo de fuentes (-1 = sin l√≠mite)
```

**Escenarios de configuraci√≥n:**

| Escenario | max_search_queries | max_results_per_query | tavily_search_depth | min_accepted_sources |
|-----------|-------------------|---------------------|---------------------|---------------------|
| **Investigaci√≥n profunda** | 5 | 10 | advanced | 8 |
| **Informe r√°pido** | 2 | 3 | basic | 3 |
| **Tema muy espec√≠fico** | 3 | 10 | advanced | -1 |
| **Overview general** | 2 | 5 | basic | 5 |

---

### 5. **Referencias y Formato**
Actualemente solo est√° activada la opci√≥n de IEEE. WiP...
```toml
[references]
enable_hyperlinks = true  # Citas [1] clicables
style = "IEEE"  # "IEEE", "APA", "MLA", etc.
```

**Estilos de referencia soportados:**
- **IEEE**: `[1] Author, "Title", Source, Year.`
- **APA**: `(Author, Year)`
- **MLA**: `Author. "Title." Source Year.`

---

## üíæ Gesti√≥n mediante Airtable

### **Tabla: Proyectos**

| Campo | Tipo | Descripci√≥n |
|-------|------|-------------|
| **Name** | Text | Nombre del proyecto |
| **Status** | Single Select | `Submitted` ‚Üí `Todo` ‚Üí `Generating items` ‚Üí `Processing` ‚Üí `Done` |
| **Items_Relacionados** | Link to Items_indice | Items que componen el proyecto |
| **Context** | Attachment | Documentos internos (solo si `context.source = "airtable"`) |
| **Consolidated_Report** | URL | Enlace al documento Word final (si `upload_to_r2 = true`) |
| **Attachment** | Attachment | Archivo Word subido autom√°ticamente |

**Estados del proyecto:**
- `Submitted`: En cola, **NO se procesa** (control manual)
- `Todo`: Listo para generar items
- `Generating items`: Procesando investigaci√≥n
- `Processing`: Consolidando documento
- `Done`: Completado ‚úÖ

---

### **Tabla: Items_indice**

| Campo | Tipo | Descripci√≥n |
|-------|------|-------------|
| **Topic** | Text | T√≠tulo del cap√≠tulo/tema |
| **Status** | Single Select | `Submitted` ‚Üí `Todo` ‚Üí `Pending` ‚Üí `Processing` ‚Üí `Done` |
| **System_Prompt_Link** | Link to System_Prompts | Agente asignado |
| **Proyectos_NEW** | Link to Proyectos | Proyecto al que pertenece |
| **Final_Report** | Long Text | Cap√≠tulo generado (Markdown) |
| **Fuentes_Acumuladas** | Long Text | Fuentes encontradas y evaluadas |
| **Sources_Count** | Number | N√∫mero de fuentes aceptadas |

**Flujo de estados:**
```
Todo ‚Üí (Matcher asigna agente) ‚Üí Pending ‚Üí (Manager inicia investigaci√≥n) ‚Üí Processing ‚Üí Done
```

**üí° Control por proyecto:**
Si el proyecto padre tiene `Status='Submitted'`, los items **NO se procesan** aunque est√©n en `Todo`.

---

### **Tabla: System_Prompts**

Define los **perfiles de experto** que gu√≠an la investigaci√≥n.

| Campo | Tipo | Contenido |
|-------|------|-----------|
| **Name** | Text | "Consultor Estrat√©gico", "Analista Financiero", etc. |
| **System_Prompt** | Long Text | Instrucciones para el agente (tono, enfoque, profundidad) |
| **Description** | Long Text | Cu√°ndo usar este perfil |

**Ejemplo de System Prompt:**
```
Eres un Consultor Estrat√©gico Senior especializado en transformaci√≥n digital.

Tu objetivo es analizar el tema desde una perspectiva de negocio:
- Enf√≥cate en ROI, casos de uso empresariales y adopci√≥n
- Incluye m√©tricas de mercado y tendencias
- Evita detalles t√©cnicos profundos
- Lenguaje claro para directivos C-level
```

---

## üõ† Instalaci√≥n y Preparaci√≥n

### **Requisitos**
- Python 3.10.19
- Conda (recomendado) o virtualenv

### **Instalaci√≥n con Conda**

```bash
# 1. Crear entorno
conda create -n deep_research python=3.10.19 -y
conda activate deep_research

# 2. Instalar dependencias
pip install -r requirements.txt

# 3. Configurar variables de entorno
cp .env.example .env
# Editar .env con tus API keys
```

### **Variables de entorno (.env)**

```env
# APIs de LLM
OPENAI_API_KEY=sk-...
GOOGLE_API_KEY=...
DEEPSEEK_API_KEY=...
OPENROUTER_API_KEY=sk-or-...

# APIs de b√∫squeda
TAVILY_API_KEY=tvly-...
EXA_API_KEY=...

# Airtable
AIRTABLE_API_KEY=pat...
AIRTABLE_BASE_ID=app...

# Cloudflare R2 (Opcional)
R2_ACCESS_KEY_ID=...
R2_SECRET_ACCESS_KEY=...
R2_ENDPOINT_URL=https://...
R2_BUCKET_NAME=...
R2_PUBLIC_DOMAIN=https://...
```

---

## üöÄ Gu√≠a de Uso

### **Modos de Ejecuci√≥n**

#### **1. Pipeline Completo (Recomendado)**
```bash
python main.py pipeline
```

Ejecuta:
1. Asignaci√≥n de agentes (`match`)
2. Investigaci√≥n de items (`items`)
3. Consolidaci√≥n de proyectos completados (`proyectos`)

**¬øCu√°ndo usar?** Flujo autom√°tico de principio a fin.

---

#### **2. Asignaci√≥n de Agentes**
```bash
python main.py match
```

- Busca items con `Status='Todo'`
- Asigna el System Prompt m√°s adecuado
- Cambia a `Status='Pending'`

**¬øCu√°ndo usar?** Solo quieres asignar agentes sin procesar.

---

#### **3. Procesamiento de Items**
```bash
python main.py items
```

- Procesa items con `Status='Pending'`
- Ejecuta b√∫squeda ‚Üí evaluaci√≥n ‚Üí s√≠ntesis
- Marca como `Done`

**¬øCu√°ndo usar?** Ya tienes agentes asignados manualmente.

---

#### **4. Consolidaci√≥n de Proyectos**
```bash
python main.py proyectos
```

- Busca proyectos con `Status='Generating items'` y todos sus items `Done`
- Consolida cap√≠tulos en documento Word
- Sube a R2 (si habilitado)

**¬øCu√°ndo usar?** Quieres forzar consolidaci√≥n de proyectos listos.

---

#### **5. Modo Servidor (Webhooks)**
```bash
python main.py server
```

Inicia servidor FastAPI en puerto 8000 (o `$PORT`).

**Endpoints:**
- `POST /webhook/process-item` ‚Üí Procesa item espec√≠fico
- `POST /webhook/pipeline` ‚Üí Ejecuta pipeline completo

**¬øCu√°ndo usar?** Despliegue en Render.com con webhooks de Airtable.

---

## üåê Despliegue en Render.com

### **Preparaci√≥n**

1. **Configurar contexto local:**
```toml
[context]
source = "local"  # Evita Docling (pesado para Render free tier)
local_folder = "private_context"
```

2. **A√±adir documentos de contexto:**
```bash
# Convertir tus PDFs a texto
pandoc company_info.pdf -o private_context/company_info.txt
```

3. **Configurar archivo `Procfile`:**
```
web: python main.py server
```

### **Variables de entorno en Render**

En el dashboard de Render, a√±ade todas las keys del `.env`:
- `OPENAI_API_KEY`
- `GOOGLE_API_KEY`
- `AIRTABLE_API_KEY`
- `AIRTABLE_BASE_ID`
- `TAVILY_API_KEY`
- `R2_*` (si usas R2)

### **Webhook de Airtable**

En Airtable Automations:

```javascript
// Trigger: When Status changes to 'Todo'
// Action: Send Webhook

let url = "https://tu-app.onrender.com/webhook/pipeline";

await fetch(url, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({})
});
```

---

## üìñ Ejemplos de Uso

### **Ejemplo 1: Informe de Mercado**

**Proyecto:** "An√°lisis del Mercado de IA en Healthcare"

**Items:**
1. "Tama√±o y crecimiento del mercado IA en salud 2024-2030"
2. "Principales players y cuota de mercado"
3. "Casos de uso: diagn√≥stico, drug discovery, operaciones"
4. "Barreras regulatorias FDA/EMA"
5. "Proyecciones de inversi√≥n VR/PE"

**Agente:** Analista de Mercado Tecnol√≥gico

**Configuraci√≥n:**
```toml
[general]
target_audience = "Inversores"
report_language = "English"

[search]
max_search_queries = 4
max_results_per_query = 8
tavily_search_depth = "advanced"

[evaluator]
min_accepted_sources = 6
```

**Resultado:** Informe de 40 p√°ginas con an√°lisis de mercado, gr√°ficos de crecimiento, tabla comparativa de empresas, y proyecciones financieras.

---

### **Ejemplo 2: Reporte T√©cnico**

**Proyecto:** "Arquitectura de Sistemas RAG para Enterprise"

**Items:**
1. "Fundamentos de Retrieval-Augmented Generation"
2. "Vector databases: comparativa Pinecone vs Weaviate"
3. "Embedding models: OpenAI vs open-source"
4. "Chunking strategies y context window optimization"
5. "Deployment en AWS/GCP"

**Agente:** Arquitecto de Soluciones IA

**Configuraci√≥n:**
```toml
[general]
target_audience = "Equipo T√©cnico"
report_language = "English"

[roles.analyst]
model = "anthropic/claude-haiku-4.5"
temperature = 0.0

[search]
excluded_domains = ["medium.com", "dev.to"]  # Solo papers y docs oficiales
```

**Resultado:** Documento t√©cnico con diagramas de arquitectura, ejemplos de c√≥digo, benchmarks, y gu√≠as de implementaci√≥n.

---

## üéì Mejores Pr√°cticas

### **1. Dise√±o del √çndice**

**‚ùå Malo (gen√©rico):**
```
- IA
- Machine Learning
- Aplicaciones
```

**‚úÖ Bueno (espec√≠fico y estructurado):**
```
- Algoritmos de IA en diagn√≥stico m√©dico por imagen
  - Computer Vision para radiolog√≠a
  - Deep Learning en anatom√≠a patol√≥gica
- Validaci√≥n cl√≠nica y m√©tricas de rendimiento
- Regulaci√≥n FDA/EMA para software m√©dico
- Casos de √©xito: Mayo Clinic, Johns Hopkins
```

---

### **2. Elecci√≥n de Agentes**

**Tema:** "Blockchain en supply chain"

**Opciones:**
- `Consultor Tecnol√≥gico` ‚Üí Enfoque en adopci√≥n empresarial
- `Desarrollador Blockchain` ‚Üí Detalles de smart contracts
- `Analista de Operaciones` ‚Üí Integraci√≥n con ERP/WMS

**Elige seg√∫n tu objetivo final.**

---

### **3. Ajuste de Thresholds**

**Para investigaci√≥n acad√©mica (m√°xima calidad):**
```toml
[evaluator]
total_score_threshold = 9
relevance_score_threshold = 9
min_accepted_sources = 8
```

**Para overview r√°pido:**
```toml
[evaluator]
total_score_threshold = 7
relevance_score_threshold = 7
min_accepted_sources = 3
```

---

## üÜò Troubleshooting

### **Problema: "No se encuentran suficientes fuentes"**

**Soluci√≥n:**
1. Reduce `min_accepted_sources` en `config.toml`
2. Baja `total_score_threshold` de 8 ‚Üí 7
3. Aumenta `max_search_queries` de 3 ‚Üí 5
4. Cambia `tavily_search_depth` a "advanced"

---

### **Problema: "El servidor se cuelga en Render"**

**Soluci√≥n:**
1. Cambia `context.source` a `"local"`
2. A√±ade documentos a `private_context/` en formato `.txt` o `.md`
3. Verifica que `concurrency_limit = 1`

---

### **Problema: "La consolidaci√≥n es muy lenta"**

**Soluci√≥n:**
- Usa `gemini-2.5-pro` para Consolidator (ventana de 2M tokens)
- Reduce n√∫mero de items por proyecto (max 10 recomendado)

---

## üìÑ Licencia

Sistema desarrollado internamente para investigaci√≥n estrat√©gica empresarial.

---

## ü§ù Soporte

Para dudas t√©cnicas o mejoras, contactar al equipo de desarrollo interno de ¬©Letsinnovate.

